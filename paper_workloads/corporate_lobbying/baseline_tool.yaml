datasets:
  legal_data:
    type: file
    path: "/Users/shreyashankar/Documents/hacking/motion-v3/paper_workloads/corporate_lobbying/legal.json"

default_model: gpt-4o-mini

operations:
  generate_search_queries:
    type: map
    prompt: |
      Given the following bill and company information:

      Bill Title: {{ input.bill_title }}
      Bill Summary: {{ input.bill_summary }}
      Company Name: {{ input.company_name }}
      Company Description: {{ input.company_description }}

      Generate a list of 3-5 Google search queries that would help determine whether this bill is relevant for the company. 
      Focus on finding information about the bill's potential impact on the company's industry or business model.

      Return the queries as a list of strings.
    tools:
      - required: true
        code: |
          def search_and_fetch(queries):
              import requests
              from bs4 import BeautifulSoup
              import json
              from concurrent.futures import ThreadPoolExecutor, as_completed

              api_key = "8ce6ffaa776e7dff67f7def44e203ca41a45e567"  # Replace with your actual Serper API key
              url = "https://google.serper.dev/search"
              
              def fetch_and_parse(result):
                  try:
                      page = requests.get(result['link'], timeout=5)
                      soup = BeautifulSoup(page.content, 'html.parser')
                      return soup.get_text()
                  except:
                      return ""

              def serper_request(query):
                  try:
                      payload = json.dumps({"q": query})
                      headers = {
                          'X-API-KEY': api_key,
                          'Content-Type': 'application/json'
                      }
                      response = requests.request("POST", url, headers=headers, data=payload)
                      results = response.json().get('organic', [])[:10]
                      
                      # Use a ThreadPoolExecutor to fetch and parse HTML for each result in parallel
                      with ThreadPoolExecutor(max_workers=10) as inner_executor:
                          futures = [inner_executor.submit(fetch_and_parse, result) for result in results]
                          article_contents = [future.result() for future in as_completed(futures)]
                      
                      # Combine query with article contents
                      return [f"Query: {query}\n\nContent: {content}" for content in article_contents if content]
                  except Exception as e:
                      return [f"Query: {query}\n\nAn error occurred: {str(e)}"]

              try:
                  with ThreadPoolExecutor(max_workers=len(queries)) as executor:
                      # Submit all queries for parallel processing
                      futures = [executor.submit(serper_request, query) for query in queries]
                      
                      # Collect results as they complete
                      all_articles = []
                      for future in as_completed(futures):
                          all_articles.extend(future.result())

                  return {"articles": all_articles}
              except Exception as e:
                  print(f"An error occurred: {str(e)}")
                  return {"articles": [f"An error occurred: {str(e)}"]}

        function:
          name: search_and_fetch
          description: Performs Google searches using provided queries, fetches the top 10 results for each query, and returns a list of articles with their corresponding search queries.
          parameters:
            type: object
            properties:
              queries:
                type: array
                items:
                  type: string
            required:
              - queries
    output:
      schema:
        articles: "list[string]"

  assess_bill_relevance:
    type: map
    output:
      schema:
        is_relevant: bool
        explanation: string
    prompt: |
      Analyze the following bill and company information, along with the additional context provided:

      Bill Title: {{ input.bill_title }}
      Bill Summary: {{ input.bill_summary }}
      Company Name: {{ input.company_name }}
      Company Description: {{ input.company_description }}

      Additional Context:
      {% for article in input.articles %}
      {{ article | truncate((16000 / input.articles|length)|int) }}
      {% endfor %}

      Determine whether this bill is relevant for the company. To do this:
      1. Identify the legal consequences of the bill.
      2. Assess whether those consequences are relevant to the company's business model, structure, or activities.
      3. Consider the additional context provided to support your assessment.

      Provide your assessment as a boolean (true/false) for relevance and a brief explanation.
    validate:
      - "isinstance(output['is_relevant'], bool)"
      - "len(output['explanation']) > 0"

pipeline:
  steps:
    - name: search_queries
      input: legal_data
      operations:
        - generate_search_queries
        - assess_bill_relevance

  output:
    type: file
    path: "/Users/shreyashankar/Documents/hacking/motion-v3/paper_workloads/corporate_lobbying/relevance_assessment_tool.json"
