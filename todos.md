TODO:

- [x] Think about fuzzy matching for reduce / entity resolution
- [x] Support equijoins
- [x] Inputs should be accessed as input['title'] instead of just title / everything be jinja
- [x] Make flatten a separate operator with flatten_key (or nothing)
- [x] Convert parallel flatmap to parallel map
- [x] Write documentation & restructure codebase
- [x] Write tests
- [x] Chunking/splitting with peripheral chunks
- [x] Write build phase
- [x] Add keys / inputs to reduce
- [x] For reduce we should pass through keys
- [x] Optimize maps
  - [x] Track costs for the optimizer
  - [x] Generate multiple plans and evaluate them instead of generating one plan
  - [x] Don't use an LLM to determine the right chunk size; try searching many chunk sizes
  - [x] Call llm agent multiple times on different random inputs & average results
  - [x] Decompose map to be a chain or parallel map
  - [ ] Debug finnicky combine prompts
- [x] Optimize resolvers (add blocking rules)
- [x] Optimize reduce
  - [x] Implement fold pattern
  - [x] Optimize folds
    - [x] Stratified sample the reduce operations based on the groupby results
    - [x] Synthesize multiple fold prompts
  - [x] Implement merge pattern
  - [ ] Optimize merges
    - [x] Synthesize merge prompts
    - [x] Derive num_parallel_folds in the reduce op itself (saving the runtimes of folds and merges)
    - [ ] Try various batch sizes
- [x] Optimize equijoins
- [x] Support multiple operator workflows in the optimizer
  - [x] Calculate explosion factor
  - [x] Incorporate selectivity estimates in the multi-operator optimization
- [x] Write gleaning optimization step
  - [ ] Incorporate gleaning in reduce
- [x] Support a summary type reduce, where we sample k elements to put in the prompt do a batch reduce
- [x] Write a non-commutative reduce
- [x] Write documentation on how all the operators work
- [x] Auto-generate resolver
- [x] Support summarizing peripheral chunks
- [x] Change validation to be pairwise comparisons (for map, at least) (Aug 14 & 15)
  - [x] Only compare the plans that are highest scoring
- [x] Support unnesting
- [x] Reduce operator: support reduce keys as list
- [x] Refactor map optimizer
- [x] In map optimizer, when creating a split, add a uuid to each record being split (instead of relying on some doc id)
- [ ] Recursively optimize operations (e.g., reduces in maps) (Aug 16 & 17 & 19)
  - [x] In map optimizer: if the submap output is a list, then we should add an unnest operation
  - [x] In reduce optimizer: query agent if we should drill-down / do a subreduce
  - [x] In map optimizer: prune the chunk size plans that don't give individually good results for the chunks
  - [x] In map optimizer: optimize the reduce operator for each chunk size plan
  - [x] In reduce optimizer: synthesize resolver if need be
  - [x] In resolve optimizer, support list-type reduce keys
- [ ] Operator reordering
  - [ ] support equivalence: map -> unnest -> reduce might be same as split -> gather -> map -> unnest -> reduce (no need to have a reduce right after map)
- [x] Run tests in CI
- [x] Support retry on validation failure
- [x] Break down split into split + gather (Aug 21 & 22)
  - [x] Support this in runner too
- [x] Support more flexible chunking strategies
  - [x] Delimiter based splitting
    - [x] Encode this in API somehow
    - [ ] Support this kind of chunking in the optimizer
  - [x] Extract headers & levels from documents, and add the level hierarchy to the chunk.
- [ ] Support tool use in operations
- [ ] Fix DSL to handle inputs like we've done in the Overleaf writeup
- [ ] Support prompts exceeding context windows; figure out how to throw out data / prioritize elements
- [ ] Support retries in the optimizers
- [ ] Write tests for optimizers
- [ ] Filter optimizer
  - [x] Extend map optimizer to support filter
  - [ ] Train an embedding classifier for filter
- [ ] Support model pools
- [ ] Support passing expectations
- [ ] Write intermediates to disk
- [ ] Support order by
- [ ] Track traces
- [ ] Reduce operations: eagerly process merges to prevent against stragglers/tail latencies in folds?
- [ ] Rewrite API for equijoin input data

Things to think about

- Filter chunks before applying the map prompt
- Reduce does not need to be an LLM call:
  - it can just be a concatenation of the inputs to the potential LLM call
  - it could also be some normal aggregation (e.g., summing up the counts of symptoms, doing a conjunction or disjunction of intermediate outputs for a filter operation)
- If the user specifies a map call in 2 different ways, they should get the same result. E.g., say they want to get a list of all the symptoms referenced in the medical transcript and what caused the symptoms.
- Resolves should support resolves within groups, not necessarily a global resolve
- Synthesize empty resolve in either builder or reduce optimizer, not both
- Figure out how to run validators when data is too large to fit in the prompt (need to randomly sample part of the document)
- In reduce optimizer: if agent suggests drill-down, see if we need to add a map to create the subreduce keys, or the subreduce key already exists
- Try various combine prompts in the reduce optimizer
- Filter optimizer: we should recursively optimize reduces if the reduce isn't good on its own
- Support retry on val failure for operations beyond map/filter
- If reduce input is too big to fit in the prompt, prompt for a map operation
