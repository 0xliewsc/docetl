TODO:

- [x] Think about fuzzy matching for reduce / entity resolution
- [x] Support equijoins
- [x] Inputs should be accessed as input['title'] instead of just title / everything be jinja
- [x] Make flatten a separate operator with flatten_key (or nothing)
- [x] Convert parallel flatmap to parallel map
- [x] Write documentation & restructure codebase
- [x] Write tests
- [x] Chunking/splitting with peripheral chunks
- [x] Write build phase
- [x] Add keys / inputs to reduce
- [x] For reduce we should pass through keys
- [x] Optimize maps
  - [x] Track costs for the optimizer
  - [x] Generate multiple plans and evaluate them instead of generating one plan
  - [x] Don't use an LLM to determine the right chunk size; try searching many chunk sizes
  - [x] Call llm agent multiple times on different random inputs & average results
  - [ ] Decompose map to be a chain or parallel map
  - [ ] Debug finnicky combine prompts
- [x] Optimize resolvers (add blocking rules)
- [x] Optimize reduce
  - [x] Implement fold pattern
  - [x] Optimize folds
    - [x] Stratified sample the reduce operations based on the groupby results
    - [x] Synthesize multiple fold prompts
  - [x] Implement merge pattern
  - [ ] Optimize merges
    - [x] Synthesize merge prompts
    - [x] Derive num_parallel_folds in the reduce op itself (saving the runtimes of folds and merges)
    - [ ] Try various batch sizes
- [x] Optimize equijoins
- [x] Support multiple operator workflows in the optimizer
  - [x] Calculate explosion factor
  - [x] Incorporate selectivity estimates in the multi-operator optimization
- [x] Write gleaning optimization step
  - [ ] Incorporate gleaning in reduce
- [ ] Write documentation on how all the operators work
- [ ] Auto-generate resolver
- [ ] Filter optimizer (as an extension of map)
- [ ] Change validation to be pairwise comparisons
- [ ] Support model pools
- [ ] Operator reordering
- [ ] Support passing expectations
- [ ] Write intermediates to disk
- [ ] Support order by
- [ ] Track traces
      l
